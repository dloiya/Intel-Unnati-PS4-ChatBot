{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate transformers datasets peft rouge","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-14T20:45:07.060024Z","iopub.execute_input":"2024-07-14T20:45:07.060932Z","iopub.status.idle":"2024-07-14T20:45:22.019223Z","shell.execute_reply.started":"2024-07-14T20:45:07.060898Z","shell.execute_reply":"2024-07-14T20:45:22.017879Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.11.1)\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.4)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Importing Necessary Libraries**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\nfrom datasets import load_dataset\nfrom peft import get_peft_model, LoraConfig\nfrom rouge import Rouge","metadata":{"execution":{"iopub.status.busy":"2024-07-14T20:59:53.710247Z","iopub.execute_input":"2024-07-14T20:59:53.710687Z","iopub.status.idle":"2024-07-14T20:59:53.717839Z","shell.execute_reply.started":"2024-07-14T20:59:53.710650Z","shell.execute_reply":"2024-07-14T20:59:53.716582Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# **Pre-Trained Model using Google FLAN T5**","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\nmodel_name = \"google/flan-t5-base\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T18:57:51.983423Z","iopub.execute_input":"2024-07-14T18:57:51.984129Z","iopub.status.idle":"2024-07-14T18:58:18.014995Z","shell.execute_reply.started":"2024-07-14T18:57:51.984100Z","shell.execute_reply":"2024-07-14T18:58:18.014098Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b3bc1ea1c54e1ea09554d93bb736d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cfd16840990488e94db241bb798af1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e28995fe6794e1ea0ae7bbc8ab765a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d114d9491fe14046b69eb06513a04477"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617aff8958d542d59b0d1e1812ade346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042150464905401e8d7831c5528b7f1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a7cc58a83f447d5902a26e66f2a11a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9844e7d7e4794d7ead33f6f4d176b9e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e8775f95ce4dc6853ec0e838136416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc924739a8674f8793f94e729f082b9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02144ce76dd84f5e9740400e87400646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda1d078046143f8aa5a31f47f30033a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0137a753254741a4c8e68d7e8023b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f293cfb6944fb690e01138dfbb72e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"483ed4342a30475d80860203f3cce66a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29fe99401a0546a496d773facb0439d7"}},"metadata":{}}]},{"cell_type":"markdown","source":"# **Training and Fine-Tuning**","metadata":{}},{"cell_type":"code","source":"def preprocess_function(examples):\n   inputs = [doc for doc in examples['article']]\n   model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n   with tokenizer.as_target_tokenizer():\n       labels = tokenizer(examples['highlights'], max_length=128, truncation=True, padding=\"max_length\")\n   model_inputs[\"labels\"] = labels[\"input_ids\"]\n   return model_inputs\nencoded_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T18:58:18.016439Z","iopub.execute_input":"2024-07-14T18:58:18.016847Z","iopub.status.idle":"2024-07-14T19:06:37.792215Z","shell.execute_reply.started":"2024-07-14T18:58:18.016811Z","shell.execute_reply":"2024-07-14T19:06:37.791229Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"712c23378ee64ab4bf263e5cd822f18e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"451cd1ca046f470eb9c9756c005c76d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"222208fa12b744b899beb95e041f7724"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = encoded_dataset[\"train\"].shuffle(seed=42).select(range(2000))\ntest_dataset = encoded_dataset[\"validation\"].shuffle(seed=42).select(range(1000))","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:06:37.794534Z","iopub.execute_input":"2024-07-14T19:06:37.794926Z","iopub.status.idle":"2024-07-14T19:06:38.127942Z","shell.execute_reply.started":"2024-07-14T19:06:37.794885Z","shell.execute_reply":"2024-07-14T19:06:38.127051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"peft_config=LoraConfig(task_type=\"CAUSAL_LM\",\n                       r=32,\n                       lora_alpha=64,\n                       lora_dropout=0.05,\n                       bias='none'\n)\nmodel=get_peft_model(model,peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:06:38.129127Z","iopub.execute_input":"2024-07-14T19:06:38.129449Z","iopub.status.idle":"2024-07-14T19:06:38.276615Z","shell.execute_reply.started":"2024-07-14T19:06:38.129422Z","shell.execute_reply":"2024-07-14T19:06:38.275604Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n   output_dir=\"./results\",\n   evaluation_strategy=\"epoch\",\n   learning_rate=1e-8,\n   per_device_train_batch_size=8,\n   per_device_eval_batch_size=8,\n   num_train_epochs=3,\n   weight_decay=0.01,\n   save_total_limit=3,\n)\n\ntrainer = Trainer(\n   model=model,\n   args=training_args,\n   train_dataset=train_dataset,\n   eval_dataset=test_dataset,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-07-14T19:06:38.278064Z","iopub.execute_input":"2024-07-14T19:06:38.278828Z","iopub.status.idle":"2024-07-14T19:18:28.576264Z","shell.execute_reply.started":"2024-07-14T19:06:38.278787Z","shell.execute_reply":"2024-07-14T19:18:28.575167Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240714_190806-prqftmty</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface/runs/prqftmty' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface' target=\"_blank\">https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface/runs/prqftmty' target=\"_blank\">https://wandb.ai/daksh-mitmpl2022-Manipal/huggingface/runs/prqftmty</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 10:04, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.565200</td>\n      <td>1.036545</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.143500</td>\n      <td>1.024374</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.118900</td>\n      <td>1.020131</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=1.6091946614583332, metrics={'train_runtime': 707.9438, 'train_samples_per_second': 8.475, 'train_steps_per_second': 2.119, 'total_flos': 4173773930496000.0, 'train_loss': 1.6091946614583332, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ndef generate_summary(example):\n    input_ids = tokenizer.encode(example[\"article\"], return_tensors=\"pt\", max_length=2048, truncation=True).to(device)\n    output = model.generate(input_ids, max_length=300, min_length=0, length_penalty=1.0, early_stopping=True)\n    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n    return {\"summary\": summary}\n\nsummaries = test_dataset.map(generate_summary, batched=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T20:00:13.627477Z","iopub.execute_input":"2024-07-14T20:00:13.627933Z","iopub.status.idle":"2024-07-14T20:38:03.075939Z","shell.execute_reply.started":"2024-07-14T20:00:13.627898Z","shell.execute_reply":"2024-07-14T20:38:03.074625Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae42fb93caa4a068a74a5c9762a7a53"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Final Result**","metadata":{}},{"cell_type":"code","source":"print(\"Article:\", test_dataset[1][\"article\"])\nprint(\"\\n-----------------------------------------------------------------------------------------\\n\")\nprint(\"Generated Summary:\", summaries[1][\"summary\"])\nprint(\"\\n-----------------------------------------------------------------------------------------\\n\")\nprint(\"Reference Summary:\", test_dataset[1]['highlights'])","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:02:33.036018Z","iopub.execute_input":"2024-07-14T21:02:33.036419Z","iopub.status.idle":"2024-07-14T21:02:33.052416Z","shell.execute_reply.started":"2024-07-14T21:02:33.036377Z","shell.execute_reply":"2024-07-14T21:02:33.051326Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Article: An anorexic teenager whose weight dropped to just five stone is fighting back from the condition by setting up a catering business. Faith March, 18 from Maldon, Essex, was surviving on nothing other than coffee when she dropped to her lowest weight in March of last year. After several ill-fated attempts to fight the illness, Faith collapsed in her bathroom where she was found by her boyfriend - and her family told her they feared for her life if she didn't get help. Scroll down for video . Faith March's weight dropped to just five stone when she was suffering from anorexia (left) but she is now in recovery and has set up her own patisserie business (right) After treatment at the Priory Hospital in Chelmsford, Faith is now at a healthier weight and credits the starting of her patisserie business, Whisk of Faith, as kick-starting her recovery. Faith said: 'This business has helped me get out of a massive hole. If I'm honest, it was a hole I never thought I would get out of. It just seemed like a never-ending cycle of problems.' Faith says she has had problems with her stomach which have baffled doctors for most of her life, but at 14 she was finally told her colon had collapsed and had surgery to insert a stent into her stomach. That returned her to some sort of normality, but in March last year her eating problems began to worsen and those around her began to notice. Faith said: 'My boyfriend, mum and dad noticed I had stopped eating again, I was just surviving on coffee,' she said. 'I was doing a cookery course at the time as well as working part time at a pub so I was surrounded by food but I just couldn't bring myself to eat anything. Faith looks happy as she poses with some of her cooking equipment and her freshly baked goods . Faith looks happy as she poses in her chefs outfit complete with an apron with the name of her company on the front . 'My boss told me to take some time out because it was clear I wasn't 100 per cent so I went to the doctors and that is when I was told I had anorexia. 'I knew I always had problems with food but to actually be diagnosed as anorexic just played havoc with my mind. Faith continued: 'I tried to combat it in so many ways that I look back on now and think 'what was I doing?' such as just staying in bed, working out at the gym all the time and just generally not accepting help. Then, a terrifying episode later that year made it hit home just how bad her problem was. Faith said: 'After one long day working from 11am until 10pm at the pub in which I hadn't eaten, my boyfriend found me collapsed on the bathroom floor. Faith's weight plummeted to just five stone but she is not much healthier (right) Pretty Faith poses with her boyfriend Alex who raised the alarm after he discovered her collapsed on the bathroom floor . 'I can't remember much about what happened but he said I couldn't go back there as I was just too unwell. 'We went on holiday and my family told me they thought I would die if I carried on working in that environment. 'It hit me then. I realised something needed to be done to save my life. Faith quit her job and spent time at home recuperating, which got her thinking about ways to get herself better. 'I always wanted my own business so Mum told me to maybe do some work for myself while I get better,' she said. 'I had been at cooking college and it was something I wanted to do for a living, so I started doing cakes and getting people ordering from me and it's just grown from there.' Brave Faith sought treatment for her anorexia at thePriory Hospital in Chelmsford . Faith says that having her new business has helped her to start eating again after suffering for years with anorexia . Mum Heather has been helping out and Faith said that, while there is still a long way to go for both her condition and her business, she is optimistic for the future. 'I still have to have check-ups twice a week but I'm weighing just over eight stone now which is a lot healthier than I was,' she said. 'My parents have been so supportive by letting me run the business from home and my boyfriend has been a tower of strength as well. 'The business started small but it has just kept growing and growing. Of course I still have bad days when I barely eat anything but as a result of starting the business I'm now eating a lot more and worrying a lot less.' Faith's Mum Heather (right) has been helping Faith with her new business Whisk of Faith .\n\n-----------------------------------------------------------------------------------------\n\nGenerated Summary: Faith March, 18, from Maldon, Essex, was surviving on nothing other than coffee when she dropped to her lowest weight in March last year. She was found by her boyfriend after she had surgery to insert a stent into her stomach. She was diagnosed with anorexia at the Priory Hospital in Chelmsford. She has set up her own patisserie business Whisk of Faith.\n\n-----------------------------------------------------------------------------------------\n\nReference Summary: Faith March's dropped to just five stone as she suffered from anorexia .\nThe 18-year-old from Essex was living on just coffee and no food .\nAfter she collapsed in the bathroom, she had hospitaltreatment .\nHas now launched a patisserie business to help her recover .\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Evaluation using ROUGE Score**","metadata":{}},{"cell_type":"code","source":"def calculate_rouge(reference_list, generated_list):\n   rouge = Rouge()\n   scores = rouge.get_scores(generated_list, reference_list)\n   rouge_1 = sum(score['rouge-1']['f'] for score in scores) / len(scores)\n   rouge_2 = sum(score['rouge-2']['f'] for score in scores) / len(scores)\n   rouge_l = sum(score['rouge-l']['f'] for score in scores) / len(scores)\n   return rouge_1, rouge_2, rouge_l\n","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:00:29.007729Z","iopub.execute_input":"2024-07-14T21:00:29.008726Z","iopub.status.idle":"2024-07-14T21:00:29.016902Z","shell.execute_reply.started":"2024-07-14T21:00:29.008690Z","shell.execute_reply":"2024-07-14T21:00:29.015617Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"reference_summaries = [example[\"highlights\"] for example in test_dataset]\ngenerated_summaries = [example[\"summary\"] for example in summaries]\n\n\nrouge_1, rouge_2, rouge_l = calculate_rouge(reference_summaries, generated_summaries)\n\nprint(\"ROUGE-1:\", rouge_1)\nprint(\"ROUGE-2:\", rouge_2)\nprint(\"ROUGE-L:\", rouge_l)","metadata":{"execution":{"iopub.status.busy":"2024-07-14T21:03:01.750276Z","iopub.execute_input":"2024-07-14T21:03:01.750706Z","iopub.status.idle":"2024-07-14T21:03:08.604188Z","shell.execute_reply.started":"2024-07-14T21:03:01.750673Z","shell.execute_reply":"2024-07-14T21:03:08.602845Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"ROUGE-1: 0.3728658283963305\nROUGE-2: 0.1587970539985485\nROUGE-L: 0.35389217770768905\n","output_type":"stream"}]},{"cell_type":"markdown","source":"ROUGE-1, on average, signifies there is a 37.29% match in unigrams between generated and reference summaries\n\nROUGE-2, on average, signifies there is a 15.88% match in bigrams betweeen generated and reference summaries\n\nROUGE-L, on average, signifies that 35.39% of the longest common subsequence of terms in the generated summaries matches that in the reference summaries.","metadata":{}}]}